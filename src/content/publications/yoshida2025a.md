---
number: 175
title: A Multi-User Multi-Robot Multi-Goal Multi-Device Human-Robot Interaction Manipulation
  Benchmark
authors: Yoshida, A., Dossa, R. F. J., Di Vincenzo, M., Sujit, S., Douglas, H., &
  Arulkumaran, K.
year: 2025
venue: Frontiers in Robotics and AI
volume: '12.0'
doi: https://doi.org/10.3389/frobt.2025.1528754
url: https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2025.1528754/abstract
type: Paper
language: en
scholar: true
abstract: One weakness of human-robot interaction (HRI) research is the lack of reproducible
  results, due to the lack of standardised benchmarks. In this work we introduce a
  multi-user multi-robot multi-goal multi-device manipulation benchmark (M4Bench),
  a flexible HRI platform in which multiple users can direct either a single—or multiple—simulated
  robots to perform a multi-goal pick-and-place task. Our software exposes a web-based
  visual interface, with support for mouse, keyboard, gamepad, eye tracker and electromyograph/electroencephalograph
  (EMG/EEG) user inputs. It can be further extended using native browser libraries
  or WebSocket interfaces, allowing researchers to add support for their own devices.
  We also provide tracking for several HRI metrics, such as task completion and command
  selection time, enabling quantitative comparisons between different user interfaces
  and devices. We demonstrate the utility of our benchmark with a user study (n =
  50) conducted to compare 5 different input devices, and also compare single-vs.
  multi-user control. In the pick-and-place task, we found that users performed worse
  when using the eye tracker + EMG device pair, as compared to mouse + keyboard or
  gamepad + gamepad, over 4 quantitative metrics (corrected p < 0.001). Our software
  is available at https://github.com/arayabrain/m4bench.
---

