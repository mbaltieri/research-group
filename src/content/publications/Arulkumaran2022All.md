---
number: 70
title: 'All You Need Is Supervised Learning: From Imitation Learning to Meta-RL With
  Upside Down RL'
authors: Arulkumaran, K., Ashley, D. R., Schmidhuber, J., & Srivastava, R. K.
year: 2022
venue: Multi-disciplinary Conference on Reinforcement Learning and Decision Making
doi: https://doi.org/10.48550/arXiv.2202.11960
url: https://arxiv.org/abs/2202.11960
type: Paper
language: en
scholar: true
abstract: 'Upside down reinforcement learning (UDRL) flips the conventional use of
  the return in the objective function in RL upside down, by taking returns as input
  and predicting actions. UDRL is based purely on supervised learning, and bypasses
  some prominent issues in RL: bootstrapping, off-policy corrections, and discount
  factors. While previous work with UDRL demonstrated it in a traditional online RL
  setting, here we show that this single algorithm can also work in the imitation
  learning and offline RL settings, be extended to the goal-conditioned RL setting,
  and even the meta-RL setting. With a general agent architecture, a single UDRL agent
  can learn across all paradigms.'
---

