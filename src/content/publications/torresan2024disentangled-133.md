---
number: 133
title: Disentangled Representations for Causal Cognition
authors: Torresan, F., & Baltieri, M.
year: 2024
venue: arXiv
doi: https://doi.org/10.48550/arXiv.2407.00744
url: https://arxiv.org/abs/2407.00744
type: Paper
language: en
scholar: true
abstract: Complex adaptive agents consistently achieve their goals by solving problems
  that seem to require an understanding of causal information, information pertaining
  to the causal relationships that exist among elements of combined agent-environment
  systems. Causal cognition studies and describes the main characteristics of causal
  learning and reasoning in human and non-human animals, offering a conceptual framework
  to discuss cognitive performances based on the level of apparent causal understanding
  of a task. Despite the use of formal intervention-based models of causality, including
  causal Bayesian networks, psychological and behavioural research on causal cognition
  does not yet offer a computational account that operationalises how agents acquire
  a causal understanding of the world. Machine and reinforcement learning research
  on causality, especially involving disentanglement as a candidate process to build
  causal representations, represent on the one hand a concrete attempt at designing
  causal artificial agents that can shed light on the inner workings of natural causal
  cognition. In this work, we connect these two areas of research to build a unifying
  framework for causal cognition that will offer a computational perspective on studies
  of animal cognition, and provide insights in the development of new algorithms for
  causal reinforcement learning in AI.
---

