---
number: 145
title: Disentangled representations for causal cognition
authors: Torresan, F., & Baltieri, M.
year: 2024
venue: Physics of Life Reviews
volume: '51.0'
pages: 343-381
doi: https://doi.org/10.1016/j.plrev.2024.10.003
url: https://www.sciencedirect.com/science/article/pii/S1571064524001295?via%3Dihub
type: Paper
language: en
scholar: true
abstract: Complex adaptive agents consistently achieve their goals by solving problems
  that seem to require an understanding of causal information, information pertaining
  to the causal relationships that exist among elements of combined agent-environment
  systems. Causal cognition studies and describes the main characteristics of causal
  learning and reasoning in human and non-human animals, offering a conceptual framework
  to discuss cognitive performances based on the level of apparent causal understanding
  of a task. Despite the use of formal intervention-based models of causality, including
  causal Bayesian networks, psychological and behavioural research on causal cognition
  does not yet offer a computational account that operationalises how agents acquire
  a causal understanding of the world seemingly from scratch, i.e. without a-priori
  knowledge of relevant features of the environment. Research on causality in machine
  and reinforcement learning, especially involving disentanglement as a candidate
  process to build causal representations, represents on the other hand a concrete
  attempt at designing artificial agents that can learn about causality, shedding
  light on the inner workings of natural causal cognition. In this work, we connect
  these two areas of research to build a unifying framework for causal cognition that
  will offer a computational perspective on studies of animal cognition, and provide
  insights in the development of new algorithms for causal reinforcement learning
  in AI.
---

